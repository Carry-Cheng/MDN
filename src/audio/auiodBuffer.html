<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Document</title>
</head>
<body>
  <script>
    var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    var button = document.querySelector('button');
    var pre = document.querySelector('pre');
    var myScript = document.querySelector('script');

    pre.innerHTML = myScript.innerHTML;

    // 立体声
    var channels = 2;
    // 创建一个 采样率与音频环境(AudioContext)相同的 时长2秒的 音频片段。
    var frameCount = audioCtx.sampleRate * 2.0;

    var myArrayBuffer = audioCtx.createBuffer(channels, frameCount, audioCtx.sampleRate);

    button.onclick = function() {
      // 使用白噪声填充;
      // 就是 -1.0 到 1.0 之间的随机数
      for (var channel = 0; channel < channels; channel++) {
      // 这允许我们读取实际音频片段(AudioBuffer)中包含的数据
      var nowBuffering = myArrayBuffer.getChannelData(channel);
      for (var i = 0; i < frameCount; i++) {
        // Math.random() is in [0; 1.0]
        // audio needs to be in [-1.0; 1.0]
        nowBuffering[i] = Math.random() * 2 - 1;
      }
      }

      // 获取一个 音频片段源节点(AudioBufferSourceNode)。
      // 当我们想播放音频片段时，我们会用到这个源节点。
      var source = audioCtx.createBufferSource();
      // 把刚才生成的片段加入到 音频片段源节点(AudioBufferSourceNode)。
      source.buffer = myArrayBuffer;
      // 把 音频片段源节点(AudioBufferSourceNode) 连接到
      // 音频环境(AudioContext) 的终节点，这样我们就能听到声音了。
      source.connect(audioCtx.destination);
      // 开始播放声源
      source.start();
    }
  </script>
</body>
</html>